{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(StyleClassifier, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.mlp = nn.Sequential(nn.Linear(input_dim,int(input_dim*0.5)),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(int(input_dim*0.5),1))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.mlp(x)\n",
    "        #x = torch.mean(x, dim=1)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x.view(x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvStyleClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(AdvStyleClassifier, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.mlp = nn.Sequential(nn.Linear(input_dim,int(input_dim*0.5)),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(int(input_dim*0.5),1))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.mlp(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x.view(x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, sequence_length):\n",
    "        super(ContentClassifier, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.sequence_length = sequence_length\n",
    "        self.mlp = nn.Sequential(nn.Linear(input_dim,int(input_dim*0.5)),\n",
    "                                  nn.ReLU(),\n",
    "                                nn.Linear(int(input_dim*0.5),sequence_length))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.mlp(x)\n",
    "        #x = torch.mean(x, dim=2)\n",
    "        x = F.softmax(x,dim=1)\n",
    "        return x.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvContentClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, sequence_length):\n",
    "        super(AdvContentClassifier, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.sequence_length = sequence_length\n",
    "        self.mlp = nn.Sequential(nn.Linear(input_dim,input_dim*2),\n",
    "                                  nn.ReLU(),\n",
    "                                nn.Linear(input_dim*2,sequence_length))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.mlp(x)\n",
    "        #x = torch.mean(x, dim=1)\n",
    "        x = F.softmax(x,dim=1)\n",
    "        return x.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUEncoder(nn.Module):\n",
    "    def __init__(self, embedding_matrix, embedd_dim, hidden_dim, latent_dim, num_layers):\n",
    "        super(GRUEncoder, self).__init__()\n",
    "        self.embedd_dim = embedd_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.style_dim = int(latent_dim/17)\n",
    "        self.content_dim = latent_dim - int(self.style_dim)\n",
    "\n",
    "        self.embedder = nn.Embedding.from_pretrained(embedding_matrix, freeze = True)\n",
    "        self.layer_norm = nn.LayerNorm(embedd_dim)\n",
    "        self.gru = nn.GRU(embedd_dim, hidden_dim, num_layers, batch_first=True) # (N,B,H) N batches, B sequence length, H input dim\n",
    "        self.fcmu_style = nn.Linear(hidden_dim, 8)\n",
    "        self.fcvar_style = nn.Linear(hidden_dim, 8)\n",
    "        self.fcmu_content = nn.Linear(hidden_dim, 128)\n",
    "        self.fcvar_content = nn.Linear(hidden_dim, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded_input = self.embedder(x)\n",
    "        x = self.layer_norm(embedded_input)\n",
    "        #h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim*2).to(x.device)\n",
    "        _, h_n = self.gru(x)\n",
    "    \n",
    "        #out = torch.norm(out,dim=2) # se vuoi usare questo MODIFICA I LINEAR LAYERS!!!!!!!!!!!!!!!!! PIUTTOSTO FAI IL NORM FUORI DALL'ENCODER E AGGIUNGI EMBEDDER A DECODER!!!!!!!!!!!!!!!!!!\n",
    "        #out = torch.mean(out,dim=1)\n",
    "        mu_s = self.fcmu_style(h_n)\n",
    "        log_var_s = self.fcvar_style(h_n)\n",
    "        mu_c = self.fcmu_content(h_n)\n",
    "        log_var_c = self.fcvar_content(h_n)\n",
    "\n",
    "        z_s = self.reparametrization(mu_s, log_var_s)\n",
    "        z_c = self.reparametrization(mu_c, log_var_c)\n",
    "        \n",
    "        return z_s, z_c, mu_s , log_var_s, mu_c, log_var_c\n",
    "    \n",
    "    def reparametrization(self,mu,log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "\n",
    "\n",
    "class GRUDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(GRUDecoder, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(latent_dim)\n",
    "        self.gru = nn.GRU(latent_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #h0 = torch.zeros(self.num_layers, x.size(0), int(self.output_dim/2)).to(x.device)\n",
    "        #out = self.embedder(x)\n",
    "        #out = self.layer_norm(out)\n",
    "        #out = self.layer_norm(x)\n",
    "        out, _ = self.gru(x)\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        #out = out.mean(dim=2)\n",
    "        #out = out.max(dim=2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_x, x, mu_s, log_var_s, mu_c, log_var_c, l_s = 0.03, l_c = 0.03, loss_fn = nn.MSELoss(), cos_loss = nn.CosineSimilarity(dim=2), wrong = nn.BCELoss()):\n",
    "    BCE = loss_fn(recon_x, x)\n",
    "    #BCE = 1 - cos_loss(recon_x,x).mean()\n",
    "    #BCE = wrong(recon_x,x)\n",
    "    KLD_s = -0.5 * torch.sum(1 + log_var_s - mu_s.pow(2) - log_var_s.exp())\n",
    "    KLD_c = -0.5 * torch.sum(1 + log_var_c - mu_c.pow(2) - log_var_c.exp())\n",
    "    return BCE + l_s*KLD_s + l_c*KLD_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul_s_loss(y_s, labels, loss_fn=nn.BCELoss()):\n",
    "    L_mul_s = loss_fn(y_s, labels)\n",
    "\n",
    "    return L_mul_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul_c_loss(y_c, bow, loss_fn=nn.MSELoss()):\n",
    "    L_mul_c = loss_fn(y_c, bow)\n",
    "\n",
    "    return L_mul_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_s_loss(y_s, labels, loss_fn=nn.BCELoss()):\n",
    "    L_dis_s = loss_fn(y_s, labels)\n",
    "\n",
    "    return L_dis_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_c_loss(y_c, bow, loss_fn=nn.MSELoss()):\n",
    "    L_dis_c = loss_fn(y_c, bow)\n",
    "\n",
    "    return L_dis_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_s_loss(y_s, loss_fn=nn.BCELoss()):\n",
    "    L_adv_s = loss_fn(y_s, y_s)\n",
    "\n",
    "    return L_adv_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_c_loss(y_c, loss_fn = nn.BCELoss()):\n",
    "    L_adv_c = loss_fn(y_c,y_c)\n",
    "\n",
    "    return L_adv_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_loss(recon_x, x, mu_s, log_var_s, mu_c, log_var_c, y_s, y_c, y_s_given_c, y_c_given_s, labels, bow, l_muls=10, l_mulc=3, l_advs=1, l_advc=0.03):\n",
    "    L_VAE = vae_loss(recon_x, x, mu_s, log_var_s, mu_c, log_var_c)\n",
    "    L_muls = mul_s_loss(y_s, labels)\n",
    "    L_mulc = mul_c_loss(y_c, bow)\n",
    "    L_advs = adv_s_loss(y_s_given_c)\n",
    "    L_advc = adv_c_loss(y_c_given_s)\n",
    "\n",
    "    return L_VAE + l_muls*L_muls + l_mulc*L_mulc - l_advs*L_advs - l_advc*L_advc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_VAE(encoder, decoder,style_classif, adv_style_classif, content_classif, adv_content_classif, train_loader, val_loader, num_epochs, vocab_size, lr = 4e-4):\n",
    "    params_tot = list(encoder.parameters()) + list(decoder.parameters()) + list(style_classif.parameters()) + list(content_classif.parameters())\n",
    "    params_dis_s = list(adv_style_classif.parameters())\n",
    "    params_dis_c = list(adv_content_classif.parameters())\n",
    "\n",
    "    optimizer_tot = torch.optim.Adam(params_tot, lr = lr)\n",
    "    optimizer_dis_s = torch.optim.Adam(params_dis_s, lr = lr)\n",
    "    optimizer_dis_c = torch.optim.Adam(params_dis_c, lr = lr)\n",
    "\n",
    "    average_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        train_loss = 0.0\n",
    "        average_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        average_val_loss = 0.0\n",
    "        \n",
    "        #model.train()\n",
    "        for  i, (data, bow, labels) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            input_data = data/vocab_size\n",
    "            labels = labels.type(torch.FloatTensor)\n",
    "            #data = torch.LongTensor(data)\n",
    "\n",
    "            optimizer_tot.zero_grad()\n",
    "            optimizer_dis_s.zero_grad()\n",
    "            optimizer_dis_c.zero_grad()\n",
    "\n",
    "            z_s, z_c, mu_s , log_var_s, mu_c, log_var_c = encoder(data)\n",
    "\n",
    "        \n",
    "            predicted_adv_style = adv_style_classif(z_c)\n",
    "            predicted_adv_style = predicted_adv_style.type(torch.FloatTensor)\n",
    "            #print('predicted adv_style shape: ', predicted_adv_style.shape)\n",
    "            #print('z content shape: ', z_content.shape)\n",
    "            \n",
    "            #return mu_style, out1, out\n",
    "            L_dis_s = dis_s_loss(predicted_adv_style, labels)\n",
    "\n",
    "            L_dis_s.backward()\n",
    "            optimizer_dis_s.step()\n",
    "\n",
    "            z_s, z_c, mu_s , log_var_s, mu_c, log_var_c = encoder(data)\n",
    "\n",
    "\n",
    "            predicted_adv_content = adv_content_classif(z_s)\n",
    "            #print('predicted adv_content shape: ', predicted_adv_content.shape)\n",
    "            #print('z style shape: ', z_style.shape)\n",
    "            #print('predicted adv_content shape: ', predicted_adv_content.shape)\n",
    "\n",
    "            L_dis_c = dis_c_loss(predicted_adv_content, bow)\n",
    "\n",
    "            L_dis_c.backward()\n",
    "            optimizer_dis_c.step()\n",
    "\n",
    "\n",
    "            z_s, z_c, mu_s , log_var_s, mu_c, log_var_c = encoder(data)\n",
    "\n",
    "            z = torch.cat((z_s,z_c),dim = 2)\n",
    "\n",
    "            \n",
    "            #mu_style = torch.norm(mu_style,dim=2)\n",
    "            #log_var_style = torch.norm(log_var_style,dim=2)\n",
    "            #mu_content = torch.norm(mu_content,dim=2)\n",
    "            #log_var_content = torch.norm(log_var_content,dim=2)\n",
    "            #print('z shape: ', z.shape)\n",
    "            \n",
    "            #z = torch.norm(z,dim=2)\n",
    "            #z = z.type(torch.LongTensor)\n",
    "            #print('new z shape: ', z.shape)\n",
    "            \n",
    "            #z_style = torch.norm(z_style,dim=2)\n",
    "            #z_content = torch.norm(z_content,dim=2)\n",
    "\n",
    "            recon_data = decoder(z)\n",
    "\n",
    "            #mu = torch.cat((mu_style,mu_content),dim=1)\n",
    "            #var = torch.cat((log_var_style.exp(),log_var_content.exp()),dim=1)\n",
    "            #log_var = torch.log(var)\n",
    "            #recon_data = torch.norm(recon_data,dim=2)\n",
    "            #recon_data = torch.mean(recon_data,dim=2) #IS THIS RIGHT?!?!?!?!?!?\n",
    "            #recon_data = recon_data[:,:,-1]\n",
    "            #print('z_style shape: ', z_style.shape)\n",
    "            #print('z content shape: ', z_content.shape)\n",
    "            #print('x reconstructed shape: ', recon_data.shape)\n",
    "            y_s = style_classif(z_s)\n",
    "            y_c = content_classif(z_c)\n",
    "            y_s_given_c = adv_style_classif(z_c)\n",
    "            y_c_given_s = adv_content_classif(z_s)\n",
    "            #print('ys shape: ', y_s.shape)\n",
    "            #print('yc shape: ', y_c.shape)\n",
    "\n",
    "            recon_data = torch.FloatTensor(recon_data)\n",
    "            \n",
    "\n",
    "            loss_tot = total_loss(recon_data.squeeze(0), input_data, mu_s, log_var_s, mu_c, log_var_c, y_s, y_c, y_s_given_c, y_c_given_s, labels, bow)\n",
    "            loss_tot.backward()\n",
    "            train_loss += loss_tot.item()\n",
    "\n",
    "            #train_loss += loss.item()\n",
    "            #VAE_loss.append(loss.detach().numpy())\n",
    "            #VAE_loss.append(loss.item())\n",
    "\n",
    "            optimizer_tot.step()\n",
    "            \n",
    "            if (i + 1) % 5000 == 0:\n",
    "                print(f'Train Epoch: {epoch+1} [{i * len(data)}/{len(train_loader.dataset)} ({100. * i / len(train_loader):.0f}%)]\\tLoss: {loss_tot.item() / len(data):.6f}')\n",
    "        \n",
    "        \n",
    "        average_loss = train_loss / len(train_loader.dataset)\n",
    "        #plt.plot(epoch+1,average_loss)\n",
    "        print(f'====> Epoch: {epoch+1} Average loss: {average_loss:.4f}')\n",
    "        average_losses.append(average_loss)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (data, bow, labels) in enumerate(val_loader):\n",
    "                data = data.to(device)\n",
    "                val_data = data/vocab_size\n",
    "                labels = labels.type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "                z_s, z_c, mu_s , log_var_s, mu_c, log_var_c = encoder(data)\n",
    "\n",
    "                z = torch.cat((z_s,z_c),dim = 2)\n",
    "\n",
    "\n",
    "                recon_data = decoder(z)\n",
    "                \n",
    "                y_s = style_classif(z_s)\n",
    "                y_c = content_classif(z_c)\n",
    "                y_s_given_c = adv_style_classif(z_c)\n",
    "                y_c_given_s = adv_content_classif(z_s)\n",
    "                \n",
    "\n",
    "                recon_data = torch.FloatTensor(recon_data)\n",
    "                \n",
    "                \n",
    "                val_loss_tot = total_loss(recon_data.squeeze(0), val_data, mu_s, log_var_s, mu_c, log_var_c, y_s, y_c, y_s_given_c, y_c_given_s, labels, bow)\n",
    "                \n",
    "                val_loss += val_loss_tot.item()\n",
    "\n",
    "\n",
    "                \n",
    "                if (i + 1) % 5000 == 0:\n",
    "                    print(f'Train Epoch: {epoch+1} [{i * len(data)}/{len(val_loader.dataset)} ({100. * i / len(val_loader):.0f}%)]\\tLoss: {val_loss_tot.item() / len(data):.6f}')\n",
    "            \n",
    "            \n",
    "        average_val_loss = val_loss / len(val_loader.dataset)\n",
    "        #print(f'====> Epoch: {epoch+1} Average loss: {average_val_loss:.4f}')\n",
    "        val_losses.append(average_val_loss)\n",
    "\n",
    "    \n",
    "    plt.plot(np.linspace(1,num_epochs,len(average_losses)), average_losses, c = 'darkcyan',label = 'train')\n",
    "    plt.plot(np.linspace(1,num_epochs,len(val_losses)), val_losses, c = 'orange',label = 'val')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    return average_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# è importantissimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomeFile='divina_commedia.txt'\n",
    "#nomeFile='malavoglia.txt'\n",
    "#nomeFile = 'uno_nessuno_e_i_malavoglia.txt'\n",
    "#nomeFile = 'tutto_assieme.txt'\n",
    "\n",
    "with open(nomeFile, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(text.split()))\n",
    "text.split()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoW(tensor):\n",
    "    bow = torch.zeros(size = (tensor.shape[0],tensor.shape[1]))\n",
    "    #BoW = [(data1[i] == num).sum().item()/data1.shape[1]  for i in range(data1.shape[0]) for num in data1[i] if BoW[i][torch.where(data1[i] == num)[0][0].item()]==0]\n",
    "\n",
    "    for i in range(tensor.shape[0]):\n",
    "        for num in tensor[i]:\n",
    "            index = torch.where(tensor[i] == num)[0][0].item()\n",
    "            bow[i][index] = (tensor[i] == num).sum().item()/tensor.shape[1]\n",
    "\n",
    "    return torch.FloatTensor(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_text(text, sequence_length):\n",
    "    words = text.split()\n",
    "    #words = text\n",
    "    grouped_words = [' '.join(words[i:i+sequence_length]) for i in range(0,len(words),int(sequence_length/4))]  # range (0,len(words),8)\n",
    "    #grouped_words = [' '.join(words[i:i+sequence_length]) for i in range(0,len(words),2)]\n",
    "    #grouped_words = [words[i] for i in range(0,len(words),19)]\n",
    "    #grouped_words_2d = [sentence.split() for sentence in grouped_words]\n",
    "    output_text = [grouped_words[i].split() for i in range(len(grouped_words)) if len(grouped_words[i].split()) == sequence_length]\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_divided = divide_text(text, 20)\n",
    "np.shape(text_divided)\n",
    "text_divided[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(text_divided, vector_size=256, window=10, min_count=1, workers=4)\n",
    "\n",
    "word2vec.train(text_divided, total_examples=word2vec.corpus_count, epochs=word2vec.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = word2vec.wv['re']\n",
    "uomo = word2vec.wv['uomo']\n",
    "donna = word2vec.wv['donna']\n",
    "corona = word2vec.wv['corona']\n",
    "il = word2vec.wv['cappello']\n",
    "italia = word2vec.wv['italia']\n",
    "parola = word2vec.wv['bella']\n",
    "#print(np.linalg.norm(uomo+donna-parola))\n",
    "word2vec.wv.most_similar(donna-uomo, topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embedding dimension\n",
    "embedding_dim = word2vec.wv.vector_size\n",
    "\n",
    "# Prepare the embedding matrix\n",
    "vocab_size = len(word2vec.wv)\n",
    "print('vocab size: ', vocab_size)\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "word2idx = {word: idx for idx, word in enumerate(word2vec.wv.index_to_key)}\n",
    "idx2word = {idx: word for idx, word in enumerate(word2vec.wv.index_to_key)}\n",
    "\n",
    "for word, idx in word2idx.items():\n",
    "    embedding_matrix[idx] = word2vec.wv[word]\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx['del']\n",
    "idx2word[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova = torch.LongTensor([[word2idx[char] for char in text_divided[i]] for i in range(len(text_divided))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova[:int(prova.shape[0]*0.9)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor([[word2idx[char] for char in text_divided[i]] for i in range(int(len(text_divided)))])\n",
    "input.shape\n",
    "#input2 = torch.tensor([[word2idx[char] for char in text_divided[i]] for i in range(int(len(text_divided)/2))])\n",
    "\n",
    "#torch.cat((input,input2),dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_dataset(file1 : str,file2 : str, sequence_length, embedding_dim, batch_size, training_fraction):\n",
    "\n",
    "    with open(file1, 'r', encoding='utf-8') as f:\n",
    "        text1 = f.read()\n",
    "\n",
    "\n",
    "    with open(file2, 'r', encoding='utf-8') as f:\n",
    "        text2 = f.read()\n",
    "\n",
    "\n",
    "    text = text1 + ' ' + text2\n",
    "    divided_text = divide_text(text, sequence_length)\n",
    "\n",
    "    #word2vec = Word2Vec(divided_text, vector_size = embedding_dim, window = int(sequence_length/2), min_count=1, workers=4)\n",
    "    word2vec = Word2Vec(divided_text, vector_size = embedding_dim, window = 5, min_count=1, workers=4)\n",
    "    word2vec.train(divided_text, total_examples=word2vec.corpus_count, epochs=20)\n",
    "\n",
    "    # Get the embedding dimension\n",
    "    embedding_dim = word2vec.wv.vector_size\n",
    "\n",
    "    # Prepare the embedding matrix\n",
    "    vocab_size = len(word2vec.wv)\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    word2idx = {word: idx for idx, word in enumerate(word2vec.wv.index_to_key)}\n",
    "    idx2word = {idx: word for idx, word in enumerate(word2vec.wv.index_to_key)}\n",
    "\n",
    "    for word, idx in word2idx.items():\n",
    "        embedding_matrix[idx] = word2vec.wv[word]\n",
    "\n",
    "    # Convert to PyTorch tensor\n",
    "    embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "    text1_divided = divide_text(text1, sequence_length)\n",
    "    data1 = torch.LongTensor([[word2idx[char] for char in text1_divided[i]] for i in range(len(text1_divided))])\n",
    "\n",
    "\n",
    "    text2_divided = divide_text(text2, sequence_length)\n",
    "    data2 = torch.LongTensor([[word2idx[char] for char in text2_divided[i]] for i in range(len(text2_divided))])\n",
    "\n",
    "\n",
    "    data1_train = data1[:int(training_fraction * data1.shape[0])]\n",
    "    data1_val = data1[int(training_fraction * data1.shape[0]):]\n",
    "\n",
    "    data2_train = data2[:int(training_fraction * data2.shape[0])]\n",
    "    data2_val = data2[int(training_fraction * data2.shape[0]):]\n",
    "\n",
    "\n",
    "    label0_train = torch.zeros(data1_train.shape[0])\n",
    "    label0_val = torch.zeros(data1_val.shape[0])\n",
    "\n",
    "    label1_train = torch.ones(data2_train.shape[0])\n",
    "    label1_val = torch.ones(data2_val.shape[0])\n",
    "\n",
    "\n",
    "    labels_train = torch.cat((label0_train, label1_train), dim = 0)\n",
    "    labels_val = torch.cat((label0_val, label1_val), dim = 0)\n",
    "\n",
    "    data_train = torch.cat((data1_train, data2_train), dim = 0)\n",
    "    data_val = torch.cat((data1_val, data2_val), dim = 0)\n",
    "\n",
    "    data_train = torch.LongTensor(data_train)\n",
    "    labels_train = labels_train.type(torch.LongTensor)\n",
    "    bow_train = BoW(data_train)\n",
    "\n",
    "    dataset_train = TensorDataset(data_train, bow_train, labels_train)\n",
    "\n",
    "    # Create a DataLoader with shuffling enabled\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size = batch_size, shuffle=True)\n",
    "    #dataloader_train = DataLoader(dataset_train, batch_size = batch_size)\n",
    "\n",
    "\n",
    "    data_val = torch.LongTensor(data_val)\n",
    "    labels_val = labels_val.type(torch.LongTensor)\n",
    "    bow_val = BoW(data_val)\n",
    "\n",
    "    dataset_val = TensorDataset(data_val, bow_val, labels_val)\n",
    "\n",
    "    # Create a DataLoader with shuffling enabled\n",
    "    dataloader_val = DataLoader(dataset_val, batch_size = batch_size, shuffle = True)\n",
    "    #dataloader_val = DataLoader(dataset_val, batch_size = batch_size)\n",
    "\n",
    "    return dataloader_train, dataloader_val, embedding_dim, embedding_matrix, word2vec, idx2word, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 20\n",
    "embedding_dim = 300\n",
    "hidden_dim = 256\n",
    "latent_dim = 136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train loader:  1143\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, embedding_dim, embedding_matrix, word2vec, idx2word, vocab_size = custom_dataset('divina_commedia.txt', \n",
    "                                                                                     'uno_nessuno_e_i_malavoglia.txt', \n",
    "                                                                                     sequence_length, \n",
    "                                                                                     embedding_dim,\n",
    "                                                                                     batch_size = 32, \n",
    "                                                                                     training_fraction = 0.9)\n",
    "print('len train loader: ', len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20248"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_encoder = GRUEncoder(embedding_matrix, embedding_dim, hidden_dim, latent_dim, 1)\n",
    "gru_decoder = GRUDecoder(latent_dim, hidden_dim, sequence_length, 1)\n",
    "\n",
    "style_classif = StyleClassifier(8)\n",
    "adv_style_classif = AdvStyleClassifier(128)\n",
    "content_classif = ContentClassifier(128, sequence_length)\n",
    "adv_content_classif = AdvContentClassifier(8, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters:  825454\n"
     ]
    }
   ],
   "source": [
    "encoder_params = sum(p.numel() for p in gru_encoder.parameters() if p.requires_grad)\n",
    "decoder_params = sum(p.numel() for p in gru_decoder.parameters() if p.requires_grad)\n",
    "style_params = sum(p.numel() for p in style_classif.parameters() if p.requires_grad)\n",
    "style_adv_params = sum(p.numel() for p in adv_style_classif.parameters() if p.requires_grad)\n",
    "content_params = sum(p.numel() for p in content_classif.parameters() if p.requires_grad)\n",
    "adv_content_params = sum(p.numel() for p in adv_content_classif.parameters() if p.requires_grad)\n",
    "total_params =  encoder_params + decoder_params +style_params + style_adv_params + content_params + adv_content_params\n",
    "print('Total parameters: ', total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1 Average loss: 0.1278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:13<11:01, 73.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 2 Average loss: 0.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [02:33<10:17, 77.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 3 Average loss: 0.0484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [03:52<09:07, 78.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 4 Average loss: 0.0425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [05:11<07:50, 78.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 5 Average loss: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [06:31<06:34, 78.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 6 Average loss: 0.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [07:51<05:17, 79.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 7 Average loss: 0.0229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [09:11<03:58, 79.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 8 Average loss: 0.0195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [10:31<02:39, 79.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 9 Average loss: 0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [11:51<01:19, 79.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 10 Average loss: 0.0178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [13:11<00:00, 79.12s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = train_VAE(gru_encoder,\n",
    "                   gru_decoder,\n",
    "                   style_classif,\n",
    "                   adv_style_classif,\n",
    "                   content_classif,\n",
    "                   adv_content_classif,\n",
    "                   train_loader,\n",
    "                   val_loader,\n",
    "                   num_epochs = 10,\n",
    "                   vocab_size= vocab_size,\n",
    "                   lr = 4e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  0\n",
      "Input sequence:  l alta provedenza che con scipio difese a roma la gloria del mondo soccorrà tosto sì com io concipio e\n",
      "Reconstructed sequence:  credere paradiso cadere pei bestie favella bianchi poveretta diletto dicer badìa corto sentii pochi destro sciara attento inferno rosso costoro\n"
     ]
    }
   ],
   "source": [
    "for i ,(data,bow,label) in enumerate(val_loader):\n",
    "    if i == 0:\n",
    "        prova = data[0]\n",
    "        labels = label[0]\n",
    "        boww = bow[0]\n",
    "\n",
    "frase = [idx2word[prova[i].item()] for i in range(prova.shape[0])]\n",
    "\n",
    "prova = prova.view(1,prova.shape[0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    z_s, z_c, mu_s , log_var_s, mu_c, log_var_c = gru_encoder(prova)\n",
    "\n",
    "    z = torch.cat((z_s,z_c),dim = 2) \n",
    "\n",
    "    out = gru_decoder(z)\n",
    "\n",
    "out = out*vocab_size\n",
    "out = out.view(sequence_length)\n",
    "\n",
    "parole = []\n",
    "\n",
    "for i in range(out.shape[0]):\n",
    "    parole.append(idx2word[int(out[i].item())])\n",
    "\n",
    "print(\"label: \", labels.item())\n",
    "print(\"Input sequence: \", ' '.join(frase))\n",
    "print(\"Reconstructed sequence: \", ' '.join(parole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  1\n",
      "Input sequence:  soffiò loro lo speziale facendo gli occhiacci volete che andiamo tutti in galera sappiate che colla giustizia bisogna dir sempre\n",
      "Reconstructed sequence:  disgrazia finalmente mentr vicario suol odo lavoro mentr alba avean manca seta buoni riguardar apposta comune fosso disgrazia potenza albero\n"
     ]
    }
   ],
   "source": [
    "for i ,(data,bow,label) in enumerate(val_loader):\n",
    "    if i == 0:\n",
    "        prova = data[0]\n",
    "        labels = label[0]\n",
    "        boww = bow[0]\n",
    "\n",
    "frase = [idx2word[prova[i].item()] for i in range(prova.shape[0])]\n",
    "\n",
    "prova = prova.view(1,prova.shape[0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    z_s, z_c, mu_s , log_var_s, mu_c, log_var_c = gru_encoder(prova)\n",
    "\n",
    "    z = torch.cat((z_s,z_c),dim = 2) \n",
    "\n",
    "    out = gru_decoder(z)\n",
    "\n",
    "out = out*vocab_size\n",
    "out = out.view(sequence_length)\n",
    "\n",
    "parole = []\n",
    "\n",
    "for i in range(out.shape[0]):\n",
    "    parole.append(idx2word[int(out[i].item())])\n",
    "\n",
    "print(\"label: \", labels.item())\n",
    "print(\"Input sequence: \", ' '.join(frase))\n",
    "print(\"Reconstructed sequence: \", ' '.join(parole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  0\n",
      "Input sequence:  vero e vede ch el s accorda con esso come nota con suo metro così la mia memoria si ricorda\n",
      "Reconstructed sequence:  camera uscì seco creatura caccia penne partito dormire anco dolor sentite disgrazia sarai faccio discorso ospedale schiera tant piano porti\n"
     ]
    }
   ],
   "source": [
    "for i ,(data,bow,label) in enumerate(val_loader):\n",
    "    if i == 0:\n",
    "        prova = data[0]\n",
    "        labels = label[0]\n",
    "        boww = bow[0]\n",
    "\n",
    "frase = [idx2word[prova[i].item()] for i in range(prova.shape[0])]\n",
    "\n",
    "prova = prova.view(1,prova.shape[0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    z_s, z_c, mu_s , log_var_s, mu_c, log_var_c = gru_encoder(prova)\n",
    "\n",
    "    z = torch.cat((z_s,z_c),dim = 2) \n",
    "\n",
    "    out = gru_decoder(z)\n",
    "\n",
    "out = out*vocab_size\n",
    "out = out.view(sequence_length)\n",
    "\n",
    "parole = []\n",
    "\n",
    "for i in range(out.shape[0]):\n",
    "    parole.append(idx2word[int(out[i].item())])\n",
    "\n",
    "print(\"label: \", labels.item())\n",
    "print(\"Input sequence: \", ' '.join(frase))\n",
    "print(\"Reconstructed sequence: \", ' '.join(parole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  1\n",
      "Input sequence:  ho trovato più niente di quel che avevo lasciato e comare mena non mi è parsa più quella uno che\n",
      "Reconstructed sequence:  fosser folle diversi signora aspetta pugni convenne suocero spirti francesco segue giudice cavallo contento tarì seco dolore belle folla dianzi\n"
     ]
    }
   ],
   "source": [
    "for i ,(data,bow,label) in enumerate(val_loader):\n",
    "    if i == 0:\n",
    "        prova = data[0]\n",
    "        labels = label[0]\n",
    "        boww = bow[0]\n",
    "\n",
    "frase = [idx2word[prova[i].item()] for i in range(prova.shape[0])]\n",
    "\n",
    "prova = prova.view(1,prova.shape[0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    z_s, z_c, mu_s , log_var_s, mu_c, log_var_c = gru_encoder(prova)\n",
    "\n",
    "    z = torch.cat((z_s,z_c),dim = 2) \n",
    "\n",
    "    out = gru_decoder(z)\n",
    "\n",
    "out = out*vocab_size\n",
    "out = out.view(sequence_length)\n",
    "\n",
    "parole = []\n",
    "\n",
    "for i in range(out.shape[0]):\n",
    "    parole.append(idx2word[int(out[i].item())])\n",
    "\n",
    "print(\"label: \", labels.item())\n",
    "print(\"Input sequence: \", ' '.join(frase))\n",
    "print(\"Reconstructed sequence: \", ' '.join(parole))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
